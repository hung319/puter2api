// main.ts
//
// CÃ¡ch cháº¡y:
// 1. Táº¡o file .env
// 2. Cháº¡y:
//    deno run --allow-net --allow-env --allow-read main.ts
//    (Váº«n cáº§n --allow-read Ä‘á»ƒ Ä‘á»c file .env)

import { Hono } from 'npm:hono@latest';
import { streamSSE } from 'npm:hono/streaming';
import { init } from 'npm:@heyputer/puter.js/src/init.cjs';
import { load } from 'https://deno.land/std@0.224.0/dotenv/mod.ts';

// 1. Táº¢I .ENV (KhÃ´ng Ä‘á»•i)
await load();

// 2. Láº¤Y AUTH TOKENS (KhÃ´ng Ä‘á»•i)
const PUTER_AUTH_TOKEN = Deno.env.get('PUTER_AUTH_TOKEN');
const SERVER_API_KEY = Deno.env.get('SERVER_API_KEY');

if (!PUTER_AUTH_TOKEN || !SERVER_API_KEY) {
  console.error("Lá»—i: PUTER_AUTH_TOKEN hoáº·c SERVER_API_KEY chÆ°a Ä‘Æ°á»£c set trong file .env");
  Deno.exit(1);
}

// 3. KHá»žI Táº O PUTER SDK (KhÃ´ng Ä‘á»•i)
const puter = init(PUTER_AUTH_TOKEN);

// ===============================================
// 4. (Cáº¬P NHáº¬T) Táº¢I MODELS VÃ€O Bá»˜ NHá»š KHI KHá»žI Äá»˜NG
// ===============================================
let modelsData: any[] = [];
const MODELS_URL = "https://puter.com/puterai/chat/models";

/**
 * HÃ m nÃ y tá»± Ä‘á»™ng cháº¡y khi server khá»Ÿi Ä‘á»™ng,
 * táº£i models tá»« URL vÃ  lÆ°u vÃ o biáº¿n 'modelsData'.
 */
async function loadModelsIntoMemory() {
  console.log(`Äang táº£i models tá»«: ${MODELS_URL}...`);
  try {
    const response = await fetch(MODELS_URL);
    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }
    
    // File models.txt chá»©a {"models": ["...", "..."]}
    const modelsJson = await response.json();
    const modelsList = modelsJson.models; 

    // Chuyá»ƒn Ä‘á»•i list string thÃ nh Ä‘á»‹nh dáº¡ng object cá»§a OpenAI
    modelsData = modelsList.map((modelId: string) => ({
      id: modelId,
      object: "model",
      created: Math.floor(Date.now() / 1000), // DÃ¹ng timestamp hiá»‡n táº¡i
      owned_by: "puter", // Giáº£ Ä‘á»‹nh
    }));
    
    console.log(`âœ… ÄÃ£ táº£i ${modelsData.length} models vÃ o bá»™ nhá»›.`);
    
  } catch (err) {
    console.error("âš ï¸ Lá»—i nghiÃªm trá»ng: KhÃ´ng thá»ƒ táº£i danh sÃ¡ch models.", err.message);
    console.error("Endpoint /v1/models sáº½ tráº£ vá» danh sÃ¡ch rá»—ng.");
    // Báº¡n cÃ³ thá»ƒ chá»n Deno.exit(1) á»Ÿ Ä‘Ã¢y náº¿u muá»‘n server dá»«ng
  }
}

// 5. Táº O HONO SERVER
const app = new Hono();

// 6. MIDDLEWARE XÃC THá»°C (KhÃ´ng Ä‘á»•i)
app.use('/v1/*', async (c, next) => {
  const authHeader = c.req.header('Authorization');
  const expectedToken = `Bearer ${SERVER_API_KEY}`;
  if (!authHeader || authHeader !== expectedToken) {
    console.warn("XÃ¡c thá»±c tháº¥t báº¡i. API key khÃ´ng há»£p lá»‡.");
    return c.json({
      error: { message: "Incorrect API key provided.", type: "invalid_request_error", code: "invalid_api_key" }
    }, 401);
  }
  await next();
});

// 7. ENDPOINT /v1/models (KhÃ´ng Ä‘á»•i, chá»‰ Ä‘á»c tá»« 'modelsData')
app.get('/v1/models', (c) => {
  console.log("GET /v1/models (ÄÃ£ xÃ¡c thá»±c)");
  return c.json({
    object: "list",
    data: modelsData, // 'modelsData' giá» Ä‘Æ°á»£c Ä‘iá»n tá»« network
  });
});

// 8. ENDPOINT /v1/chat/completions (KhÃ´ng Ä‘á»•i)
app.post('/v1/chat/completions', async (c) => {
  // (ToÃ n bá»™ logic xá»­ lÃ½ chat giá»¯ nguyÃªn y há»‡t)
  console.log("POST /v1/chat/completions (ÄÃ£ xÃ¡c thá»±c)");
  const body = await c.req.json();
  const isStream = body.stream ?? false;
  const messages = body.messages;

  if (!messages || !Array.isArray(messages) || messages.length === 0) {
    return c.json({ error: "Request thiáº¿u máº£ng 'messages'" }, 400);
  }

  const puterOptions: { [key: string]: any } = {
    model: body.model,
    stream: isStream,
  };
  
  if (body.max_tokens) puterOptions.max_tokens = body.max_tokens;
  if (body.temperature) puterOptions.temperature = body.temperature;
  if (body.tools) puterOptions.tools = body.tools;

  try {
    if (isStream) {
      const puterStream = await puter.ai.chat(messages, puterOptions);
      const modelId = `chatcmpl-${Date.now()}`;

      return streamSSE(c, async (stream) => {
        for await (const part of puterStream) {
          const content = part?.text || ""; 
          if (content) {
            const openAIChunk = {
              id: modelId,
              object: "chat.completion.chunk",
              created: Math.floor(Date.now() / 1000),
              model: body.model,
              choices: [
                { index: 0, delta: { content: content }, finish_reason: null },
              ],
            };
            await stream.writeSSE({ data: JSON.stringify(openAIChunk) });
          }
        }
        const endChunk = {
          id: modelId,
          object: "chat.completion.chunk",
          created: Math.floor(Date.now() / 1000),
          model: body.model,
          choices: [
            { index: 0, delta: {}, finish_reason: "stop" },
          ],
        };
        await stream.writeSSE({ data: JSON.stringify(endChunk) });
        await stream.writeSSE({ data: '[DONE]' });
      });
    }

    // Non-streaming
    const puterResponse = await puter.ai.chat(messages, puterOptions);
    let responseMessage;
    if (typeof puterResponse === 'string') {
        responseMessage = { role: "assistant", content: puterResponse };
    } else if (puterResponse && puterResponse.message) {
        responseMessage = puterResponse.message;
    } else if (puterResponse && puterResponse.text) {
        responseMessage = { role: "assistant", content: puterResponse.text };
    } else {
        responseMessage = { role: "assistant", content: JSON.stringify(puterResponse) };
    }

    const openAIResponse = {
      id: `chatcmpl-${Date.now()}`,
      object: "chat.completion",
      created: Math.floor(Date.now() / 1000),
      model: body.model,
      choices: [
        { index: 0, message: responseMessage, finish_reason: "stop" },
      ],
      usage: { prompt_tokens: 0, completion_tokens: 0, total_tokens: 0 },
    };
    return c.json(openAIResponse);

  } catch (err) {
    console.error("Lá»—i khi gá»i API cá»§a Puter:", err);
    return c.json({ error: "Lá»—i tá»« upstream Puter API", details: err.message }, 502);
  }
});

// 9. HEALTH CHECK (KhÃ´ng Ä‘á»•i)
app.get('/', (c) => {
  return c.text('Puter.js (Deno) OpenAI-compatible Proxy (v4 - In-Memory) is running!');
});

// 10. KHá»žI Äá»˜NG SERVER
console.log("âœ… ÄÃ£ táº£i cáº¥u hÃ¬nh tá»« .env");

// Cháº¡y hÃ m táº£i models TRÆ¯á»šC khi khá»Ÿi Ä‘á»™ng server
await loadModelsIntoMemory(); 

console.log("âœ… Server Deno (Proxy Puter.js v4) Ä‘ang cháº¡y táº¡i: http://localhost:8000");
console.log("ðŸ”’ CÃ¡c endpoint /v1/* Ä‘Ã£ Ä‘Æ°á»£c báº£o vá»‡ báº±ng SERVER_API_KEY.");

Deno.serve({
  port: 8000,
  onListen: ({ port, hostname }) => {
    console.log(`ðŸ“¡ Listening on http://${hostname}:${port}`);
  },
  fetch: app.fetch,
});

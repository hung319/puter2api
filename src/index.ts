// src/index.ts

// 1. KHÃ”NG Cáº¦N import 'dotenv/config'
// Bun tá»± Ä‘á»™ng táº£i file .env

import { Hono } from 'hono';
import { streamSSE } from 'hono/streaming';
import { puter } from '@heyputer/puter.js'; // Import NPM chuáº©n

// 2. KHÃ”NG Cáº¦N import { serve } from '@hono/node-server'

// 3. Láº¤Y AUTH TOKENS (dÃ¹ng process.env)
// Bun cÅ©ng há»— trá»£ process.env
const PUTER_AUTH_TOKEN = process.env.PUTER_AUTH_TOKEN;
const SERVER_API_KEY = process.env.SERVER_API_KEY;

if (!PUTER_AUTH_TOKEN || !SERVER_API_KEY) {
  console.error("Lá»—i: PUTER_AUTH_TOKEN hoáº·c SERVER_API_KEY chÆ°a Ä‘Æ°á»£c set trong file .env");
  process.exit(1);
}

// 4. KHá»I Táº O PUTER SDK (KhÃ´ng Ä‘á»•i)
console.log("âœ… ÄÃ£ khá»Ÿi táº¡o Puter client (tá»± Ä‘á»™ng).");

// 5. Táº¢I MODELS VÃ€O Bá»˜ NHá»š (KhÃ´ng Ä‘á»•i)
let modelsData: any[] = [];
const MODELS_URL = "https://puter.com/puterai/chat/models";

async function loadModelsIntoMemory() {
  console.log(`Äang táº£i models tá»«: ${MODELS_URL}...`);
  try {
    const response = await fetch(MODELS_URL); // fetch() lÃ  native trong Bun
    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }
    const modelsJson = await response.json();
    const modelsList = modelsJson.models; 
    modelsData = modelsList.map((modelId: string) => ({
      id: modelId,
      object: "model",
      created: Math.floor(Date.now() / 1000),
      owned_by: "puter",
    }));
    console.log(`âœ… ÄÃ£ táº£i ${modelsData.length} models vÃ o bá»™ nhá»›.`);
  } catch (err) {
    console.error("âš ï¸ Lá»—i nghiÃªm trá»ng: KhÃ´ng thá»ƒ táº£i danh sÃ¡ch models.", (err as Error).message);
  }
}

// 6. Táº O HONO SERVER (KhÃ´ng Ä‘á»•i)
const app = new Hono();

// 7. MIDDLEWARE XÃC THá»°C (KhÃ´ng Ä‘á»•i)
app.use('/v1/*', async (c, next) => {
  const authHeader = c.req.header('Authorization');
  const expectedToken = `Bearer ${SERVER_API_KEY}`;
  if (!authHeader || authHeader !== expectedToken) {
    console.warn("XÃ¡c thá»±c tháº¥t báº¡i. API key khÃ´ng há»£p lá»‡.");
    return c.json({
      error: { message: "Incorrect API key provided.", type: "invalid_request_error", code: "invalid_api_key" }
    }, 401);
  }
  await next();
});

// 8. ENDPOINT /v1/models (KhÃ´ng Ä‘á»•i)
app.get('/v1/models', (c) => {
  console.log("GET /v1/models (ÄÃ£ xÃ¡c thá»±c)");
  return c.json({ object: "list", data: modelsData });
});

// 9. ENDPOINT /v1/chat/completions (KhÃ´ng Ä‘á»•i)
app.post('/v1/chat/completions', async (c) => {
  // ... (Logic y há»‡t nhÆ° trÆ°á»›c, khÃ´ng cáº§n thay Ä‘á»•i)
  console.log("POST /v1/chat/completions (ÄÃ£ xÃ¡c thá»±c)");
  const body = await c.req.json();
  const isStream = body.stream ?? false;
  const messages = body.messages;
  if (!messages || !Array.isArray(messages) || messages.length === 0) {
    return c.json({ error: "Request thiáº¿u máº£ng 'messages'" }, 400);
  }
  const puterOptions: { [key: string]: any } = {
    model: body.model,
    stream: isStream,
  };
  if (body.max_tokens) puterOptions.max_tokens = body.max_tokens;
  if (body.temperature) puterOptions.temperature = body.temperature;
  if (body.tools) puterOptions.tools = body.tools;

  try {
    if (isStream) {
      const puterStream = await puter.ai.chat(messages, puterOptions);
      const modelId = `chatcmpl-${Date.now()}`;
      return streamSSE(c, async (stream) => {
        for await (const part of puterStream) {
          const content = part?.text || ""; 
          if (content) {
            const openAIChunk = {
              id: modelId, object: "chat.completion.chunk", created: Math.floor(Date.now() / 1000), model: body.model,
              choices: [{ index: 0, delta: { content: content }, finish_reason: null }],
            };
            await stream.writeSSE({ data: JSON.stringify(openAIChunk) });
          }
        }
        const endChunk = {
          id: modelId, object: "chat.completion.chunk", created: Math.floor(Date.now() / 1000), model: body.model,
          choices: [{ index: 0, delta: {}, finish_reason: "stop" }],
        };
        await stream.writeSSE({ data: JSON.stringify(endChunk) });
        await stream.writeSSE({ data: '[DONE]' });
      });
    }
    const puterResponse = await puter.ai.chat(messages, puterOptions);
    let responseMessage;
    if (typeof puterResponse === 'string') {
        responseMessage = { role: "assistant", content: puterResponse };
    } else if (puterResponse && puterResponse.message) {
        responseMessage = puterResponse.message;
    } else if (puterResponse && puterResponse.text) {
        responseMessage = { role: "assistant", content: puterResponse.text };
    } else {
        responseMessage = { role: "assistant", content: JSON.stringify(puterResponse) };
    }
    const openAIResponse = {
      id: `chatcmpl-${Date.now()}`, object: "chat.completion", created: Math.floor(Date.now() / 1000), model: body.model,
      choices: [{ index: 0, message: responseMessage, finish_reason: "stop" }],
      usage: { prompt_tokens: 0, completion_tokens: 0, total_tokens: 0 },
    };
    return c.json(openAIResponse);
  } catch (err) {
    console.error("Lá»—i khi gá»i API cá»§a Puter:", (err as Error).message);
    return c.json({ error: "Lá»—i tá»« upstream Puter API", details: (err as Error).message }, 502);
  }
});

// 10. HEALTH CHECK (KhÃ´ng Ä‘á»•i)
app.get('/', (c) => {
  return c.text('Puter.js (Bun) OpenAI-compatible Proxy (v7) is running!');
});

// 11. KHá»I Äá»˜NG SERVER (dÃ¹ng Bun.serve)
async function startServer() {
  console.log("âœ… ÄÃ£ táº£i cáº¥u hÃ¬nh tá»« .env (tá»± Ä‘á»™ng)");
  await loadModelsIntoMemory(); 

  const port = parseInt(process.env.PORT || '8000');
  
  console.log(`âœ… Server Bun (Proxy Puter.js v7) Ä‘ang cháº¡y táº¡i: http://localhost:${port}`);
  console.log("ğŸ”’ CÃ¡c endpoint /v1/* Ä‘Ã£ Ä‘Æ°á»£c báº£o vá»‡ báº±ng SERVER_API_KEY.");

  // CÃº phÃ¡p cá»§a Bun.serve (giá»‘ng Deno)
  Bun.serve({
    fetch: app.fetch,
    port: port
  });
}

startServer();
